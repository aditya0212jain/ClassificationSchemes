{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mykMeans:\n",
    "\n",
    "    def __init__(self,k,n,d):\n",
    "        # k is the number of clusters to form\n",
    "        self.k = k\n",
    "        # centroid points\n",
    "        self.centroid = np.zeros(k*d).reshape(k,d)\n",
    "        # weights are the how much each feature matters\n",
    "        self.weights = np.ones(d)\n",
    "        # d is the dimension of the feature vector\n",
    "        self.d = d\n",
    "        # n is the number of the samples we have\n",
    "        self.n = n\n",
    "        #cluster is the stored value of the data\n",
    "        self.cluster = np.zeros(n)\n",
    "\n",
    "    def showValues(self):\n",
    "        print(\"k:\",self.k)\n",
    "        print(\"n:\",self.n)\n",
    "        print(\"d:\",self.d)\n",
    "\n",
    "    def weights(self,data):\n",
    "        for i in range (0,self.d):\n",
    "            # for now the weights are set as 1\n",
    "            self.weights[i]=1\n",
    "\n",
    "    def dis(self,data,centroidIndex):\n",
    "        distance =0\n",
    "        #using euclidean distance with weights in this case\n",
    "        for i in range (0,self.d):\n",
    "            distance = distance + (self.weights[i]*((data[i]-self.centroid[centroidIndex][i])**2))\n",
    "        return distance\n",
    "\n",
    "    def updateClass(self,data):\n",
    "#         print('n in update class: ',self.n)\n",
    "        for i in range (0,self.n):\n",
    "            minDistance = math.inf\n",
    "#             print(\"i in updateClass: \",i)\n",
    "            for j in range (0,self.k):\n",
    "                tempDist = self.dis(data[i],j)\n",
    "                if(tempDist<minDistance):\n",
    "                    self.cluster[i] = j\n",
    "                    minDistance = tempDist\n",
    "                    # print('cluster: ',j)\n",
    "        # self.printAllClasses()\n",
    "\n",
    "    def updateCentroids(self,data):\n",
    "        converged = True\n",
    "        tempCentroid = np.zeros(self.k*self.d).reshape(self.k,self.d)\n",
    "        tempCnumbers = np.zeros(self.k)\n",
    "        for i in range(0,self.n):\n",
    "            clusIndex = (int)(self.cluster[i])\n",
    "            # print('clusindex for i:',i,clusIndex)\n",
    "            tempCnumbers[clusIndex]+=1\n",
    "            tempCentroid[clusIndex]+=data[i]\n",
    "        for i in range(0,self.k):\n",
    "            t = (tempCentroid[i]/tempCnumbers[i])==self.centroid[i]\n",
    "            for j in range(0,self.d):\n",
    "                if(t[j]==False):\n",
    "                    converged = False\n",
    "                    break\n",
    "            self.centroid[i] = tempCentroid[i]/tempCnumbers[i]\n",
    "        return converged\n",
    "\n",
    "    def initializeCentroids(self,data):\n",
    "        #right now it takes only the first k elements\n",
    "        for i in range(0,self.k):\n",
    "            self.centroid[i] = data[random.randint(0,self.n-1)]\n",
    "    \n",
    "    def initKMeansPlusPlus(self,data):\n",
    "        ##KMeans++ implementation\n",
    "        self.centroid[0] = data[random.randint(0,self.n-1)]\n",
    "        for i in range(1,self.k):\n",
    "            distArr = []\n",
    "            for j in range(self.n):\n",
    "                mindist = math.inf\n",
    "                for k in range(i):\n",
    "                    tempDist = self.dis(data[j],k)\n",
    "                    if mindist>tempDist:\n",
    "                        mindist=tempDist\n",
    "                distArr.append(mindist)\n",
    "            distArr = np.array(distArr)\n",
    "            probs = distArr/(np.sum(distArr))\n",
    "            cumprobs = np.cumsum(probs)\n",
    "            r = scipy.rand()\n",
    "            for s,t in enumerate(cumprobs):\n",
    "                if r<t:\n",
    "                    self.centroid[i] = data[s]\n",
    "                    break\n",
    "            \n",
    "                \n",
    "    def classify(self,data,max_iter,kmplusplus=0):\n",
    "        convergence = False\n",
    "        if(kmplusplus==0):\n",
    "            self.initializeCentroids(data)\n",
    "        else:\n",
    "            print(\"KMEANS++\")\n",
    "            self.initKMeansPlusPlus(data)\n",
    "        p=0\n",
    "        while((convergence==False) and (p!=max_iter)):\n",
    "            print(p)\n",
    "            p+=1\n",
    "            self.updateClass(data)\n",
    "            convergence = self.updateCentroids(data)\n",
    "        print(\"Classification Done\")\n",
    "#         print(\"Now printing cluster values:\")\n",
    "#         self.printAllClasses()\n",
    "\n",
    "    def getClass(self,data):\n",
    "        minDistance = math.inf\n",
    "        clusterNumber = -1\n",
    "        for j in range (0,self.k):\n",
    "            tempDist = self.dis(data,j)\n",
    "            if(tempDist<minDistance):\n",
    "                clusterNumber = j\n",
    "                minDistance = tempDist\n",
    "        return clusterNumber\n",
    "    \n",
    "    def getClassForAll(self,data):\n",
    "        n = data.shape[0]\n",
    "        ansList=[]\n",
    "        for i in range(n):\n",
    "            ans = self.getClass(data[i])\n",
    "            ansList.append(ans)\n",
    "#             print(ans)\n",
    "        return ansList\n",
    "        \n",
    "    def printAllClasses(self):\n",
    "        for i in range(0,self.n):\n",
    "            print(self.cluster[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self,m):\n",
    "        self.m = m\n",
    "        \n",
    "    def dimensionReduction(self,data):\n",
    "        # data is of the form n X d , with d dimensions\n",
    "        self.d = data.shape[1]\n",
    "        self.n = data.shape[0]\n",
    "        #data -= np.mean(data,axis=0)\n",
    "        S = np.cov(data.T)\n",
    "        w,v = np.linalg.eig(S)\n",
    "        #w is the array of eigen values and v's are the corresponding eigen vectors\n",
    "        # for w[i] -> v[:,i] is the corresponding eigen vectors\n",
    "        tempList = []\n",
    "        for i in range(self.d):\n",
    "            tempList.append((w[i],i))\n",
    "        tempList.sort(reverse=True)\n",
    "        tempVecList = []\n",
    "        for i in range(self.m):\n",
    "            tempVecList.append(v[:,tempList[i][1]])\n",
    "        finalVecMat = np.array(tempVecList) # m X d\n",
    "        reducedMat = np.matmul(finalVecMat,data.T) # m X n\n",
    "        return reducedMat.T # n X m , dimension reduced from d -> m\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "#                                                    Testing kMeans\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "#  for medical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Medical_data.csv','r') as csv_file:\n",
    "    csv_reader = list(csv.reader(csv_file,delimiter=\",\"))\n",
    "    csv_dicReader = csv.DictReader(csv_file)\n",
    "    my_data = np.array(csv_reader)\n",
    "    my_data = my_data[1:,:]\n",
    "    np.random.shuffle(my_data)\n",
    "    input_data = np.array(my_data[:,1:],dtype=np.float)\n",
    "    tag_data = np.array(my_data[:, 0],dtype=np.string_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMEANS++\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "Classification Done\n"
     ]
    }
   ],
   "source": [
    "obj = mykMeans(3,3000,3)\n",
    "trainingData = input_data[:,:]\n",
    "#pass 1 as third parameter for kmeans++\n",
    "obj.classify(trainingData,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansList = obj.getClassForAll(input_data[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "permu = list(itertools.permutations([0,1,2]))\n",
    "minall = math.inf\n",
    "ansClust = []\n",
    "c1=2\n",
    "c2=1\n",
    "c3=0\n",
    "for i in range(0,3000):\n",
    "    if(tag_data[i]==b'HEALTHY'):\n",
    "        ansClust.append(c1)\n",
    "    elif(tag_data[i]==b'SURGERY'):\n",
    "        ansClust.append(c2)\n",
    "    elif(tag_data[i]==b'MEDICATION'):\n",
    "        ansClust.append(c3)\n",
    "for i in range(len(permu)):\n",
    "#     print(i)\n",
    "    ansListDup= ansList\n",
    "    errcount =0\n",
    "    for j in range(len(ansListDup)):\n",
    "        ansListDup[j] = permu[i][ansListDup[j]]\n",
    "#         print('permu: '+str(permu[i]))\n",
    "        if ansListDup[j]!=ansClust[j]:\n",
    "            errcount+=1\n",
    "    minall = min(minall,errcount)\n",
    "print(minall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### below is the scikit one==================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "skmeans =KMeans(n_clusters=3)\n",
    "skmeans.fit(input_data)\n",
    "ans = skmeans.labels_\n",
    "ansList = skmeans.labels_\n",
    "tl = ans==ansClust\n",
    "errcount=0\n",
    "for p in range(3000):\n",
    "    if tl[p]==False:\n",
    "        errcount+=1\n",
    "print(errcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "#         Fashion -Mnist dataset\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "scriptpath = \"./fashion-mnist/utils\"\n",
    "\n",
    "# Add the directory containing your module to the Python path (wants absolute paths)\n",
    "sys.path.append(os.path.abspath(scriptpath))\n",
    "import mnist_reader\n",
    "X_train, Y_train = mnist_reader.load_mnist('./fashion-mnist/data/fashion', kind='train')\n",
    "X_test, Y_test = mnist_reader.load_mnist('./fashion-mnist/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pcaObj = PCA(10)\n",
    "    reducedTrain = pcaObj.dimensionReduction(X_train)\n",
    "    reducedTest = pcaObj.dimensionReduction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMEANS++\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "Classification Done\n"
     ]
    }
   ],
   "source": [
    "obj = mykMeans(10,10000,10)\n",
    "# give 1 as third parameter for kmeans\n",
    "obj.classify(reducedTest,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansList = obj.getClassForAll(reducedTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5740\n"
     ]
    }
   ],
   "source": [
    "###############################Checking answer for fashion Mnist \n",
    "maparr =np.zeros(100).reshape(10,10)\n",
    "for i in range(10000):\n",
    "    maparr[int(ansList[i])][Y_test[i]]+=1\n",
    "maplist= np.zeros(10).reshape(10,1)\n",
    "for i in range(10):\n",
    "    maxi = -1*math.inf\n",
    "    index=-1\n",
    "    for j in range(10):\n",
    "        if max(maxi,maparr[i][j])!=maxi:\n",
    "            maxi=maparr[i][j]\n",
    "            index=j\n",
    "    maplist[i]=index\n",
    "for i in range(10000):\n",
    "    ansList[i] = maplist[int(ansList[i])]\n",
    "ansList = np.array(ansList)\n",
    "ansClust = np.array(Y_test)\n",
    "errcount=0\n",
    "for p in range(10000):\n",
    "    if ansClust[p]!=ansList[p]:\n",
    "        errcount+=1\n",
    "print(errcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################Scikit learn for fashion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmeans =KMeans(n_clusters=10)\n",
    "skmeans.fit(reducedTest)\n",
    "# ans = skmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4417\n"
     ]
    }
   ],
   "source": [
    "#############################Checking answer for scikit learn for fashion mnist\n",
    "ansList = skmeans.labels_\n",
    "maparr =np.zeros(100).reshape(10,10)\n",
    "for i in range(10000):\n",
    "    maparr[int(ansList[i])][Y_test[i]]+=1\n",
    "maplist= np.zeros(10).reshape(10,1)\n",
    "for i in range(10):\n",
    "    maxi = -1*math.inf\n",
    "    index=-1\n",
    "    for j in range(10):\n",
    "        if max(maxi,maparr[i][j])!=maxi:\n",
    "            maxi=maparr[i][j]\n",
    "            index=j\n",
    "    maplist[i]=index\n",
    "for i in range(10000):\n",
    "    ansList[i] = maplist[int(ansList[i])]\n",
    "ansList = np.array(ansList)\n",
    "ansClust = np.array(Y_test)\n",
    "errcount=0\n",
    "for p in range(10000):\n",
    "    if ansClust[p]!=ansList[p]:\n",
    "        errcount+=1\n",
    "print(errcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
